{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c89fbf2b-2de8-4a8d-afa2-7bcdd5c55616",
   "metadata": {},
   "source": [
    "# Project 3 - A Tale of Two Subreddits \n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d0ae416-cffc-4e1e-bb1e-f36fa7509b06",
   "metadata": {},
   "source": [
    "## Modeling\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4de1066-0df2-4c53-b5da-0754fdf142ff",
   "metadata": {},
   "source": [
    "Now that the data cleaning is complete, we can move on to modeling. As previously stated, this will mean creating a Random Forest Classifier and a Naive Bayes Classifier. Before moving on, recall that the baseline accuracy for this data is **50.5%**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "075d9a58-4687-4d6d-aea4-4de02ef955c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# But first, imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import nltk\n",
    "\n",
    "# Modeling imports\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "08f5e770-300a-40b0-a808-c5eda368efc8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>selftext</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>Target_col</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Conservative</td>\n",
       "      <td>John Kerry Declares Biden Administration Will ...</td>\n",
       "      <td>John Kerry Declares Biden Administration Will...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Conservative</td>\n",
       "      <td>Illegal Immigration and ‘Racial Equity’</td>\n",
       "      <td>Illegal Immigration and ‘Racial Equity’</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[deleted]</td>\n",
       "      <td>Conservative</td>\n",
       "      <td>Of course it is</td>\n",
       "      <td>[deleted] Of course it is</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[removed]</td>\n",
       "      <td>Conservative</td>\n",
       "      <td>The Future of the GOP</td>\n",
       "      <td>[removed] The Future of the GOP</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Conservative</td>\n",
       "      <td>Joe Biden to Ban New Fracking Leases on Federa...</td>\n",
       "      <td>Joe Biden to Ban New Fracking Leases on Feder...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    selftext     subreddit                                              title  \\\n",
       "0        NaN  Conservative  John Kerry Declares Biden Administration Will ...   \n",
       "1        NaN  Conservative            Illegal Immigration and ‘Racial Equity’   \n",
       "2  [deleted]  Conservative                                    Of course it is   \n",
       "3  [removed]  Conservative                              The Future of the GOP   \n",
       "4        NaN  Conservative  Joe Biden to Ban New Fracking Leases on Federa...   \n",
       "\n",
       "                                                text  Target_col  \n",
       "0   John Kerry Declares Biden Administration Will...           0  \n",
       "1            Illegal Immigration and ‘Racial Equity’           0  \n",
       "2                          [deleted] Of course it is           0  \n",
       "3                    [removed] The Future of the GOP           0  \n",
       "4   Joe Biden to Ban New Fracking Leases on Feder...           0  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load in the cleaned data\n",
    "data = pd.read_csv('../datasets/raw_text_data.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "fa2c02b0-3bc9-4dda-b873-9ccadd8ed742",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grab the needed data and split the data\n",
    "X = data['title']\n",
    "y = data['Target_col']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3bba5469-1e48-4b14-8500-f434771fa1ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6798,)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3be471a3-2416-4ea5-ab7c-ad8f091d0e47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6798,)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c56c7b38-9a5d-43a9-a989-4bf7ba2ed4e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add in the stop words list\n",
    "stop_words = nltk.corpus.stopwords.words('english')\n",
    "stop_words_plus = stop_words + ['removed', 'deleted']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d169ba91-c305-4922-a2c6-24b53bdaead1",
   "metadata": {},
   "source": [
    "### The Random Forest Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3517e53c-e6b1-4a4f-bb10-1cddf2f02d77",
   "metadata": {},
   "source": [
    "To create a Random Forest Classfier, I will utilize a Pipeline with the TF-IDF word vectorizer along with the estimator. This will allow me to tune the hyperparameters of both in a grid search:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "196c022e-0f5c-4526-b6e8-ec8a3747274b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up a counter and empty dict to store model params in\n",
    "model_params_rf = {}\n",
    "count_rf = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "1423fc33-7e6b-422b-99ad-f3b20047a40e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 288 candidates, totalling 1440 fits\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rf__ccp_alpha</th>\n",
       "      <th>rf__max_depth</th>\n",
       "      <th>rf__max_features</th>\n",
       "      <th>rf__min_samples_split</th>\n",
       "      <th>rf__n_estimators</th>\n",
       "      <th>tvec__max_features</th>\n",
       "      <th>tvec__ngram_range</th>\n",
       "      <th>tvec__stop_words</th>\n",
       "      <th>training_score</th>\n",
       "      <th>test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>model_1</th>\n",
       "      <td>0.0010</td>\n",
       "      <td>4</td>\n",
       "      <td>auto</td>\n",
       "      <td>3</td>\n",
       "      <td>120</td>\n",
       "      <td>2000</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>None</td>\n",
       "      <td>0.638569</td>\n",
       "      <td>0.632833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model_2</th>\n",
       "      <td>0.0010</td>\n",
       "      <td>5</td>\n",
       "      <td>auto</td>\n",
       "      <td>3</td>\n",
       "      <td>120</td>\n",
       "      <td>2000</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>None</td>\n",
       "      <td>0.639303</td>\n",
       "      <td>0.628861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model_3</th>\n",
       "      <td>0.0001</td>\n",
       "      <td>6</td>\n",
       "      <td>auto</td>\n",
       "      <td>2</td>\n",
       "      <td>120</td>\n",
       "      <td>2000</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>None</td>\n",
       "      <td>0.643127</td>\n",
       "      <td>0.634157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model_4</th>\n",
       "      <td>0.0001</td>\n",
       "      <td>9</td>\n",
       "      <td>auto</td>\n",
       "      <td>3</td>\n",
       "      <td>140</td>\n",
       "      <td>2000</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>None</td>\n",
       "      <td>0.651806</td>\n",
       "      <td>0.643866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model_5</th>\n",
       "      <td>0.0001</td>\n",
       "      <td>15</td>\n",
       "      <td>auto</td>\n",
       "      <td>2</td>\n",
       "      <td>140</td>\n",
       "      <td>2000</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>[i, me, my, myself, we, our, ours, ourselves, ...</td>\n",
       "      <td>0.668725</td>\n",
       "      <td>0.667255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model_6</th>\n",
       "      <td>0.0001</td>\n",
       "      <td>30</td>\n",
       "      <td>auto</td>\n",
       "      <td>3</td>\n",
       "      <td>120</td>\n",
       "      <td>2000</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>[i, me, my, myself, we, our, ours, ourselves, ...</td>\n",
       "      <td>0.686671</td>\n",
       "      <td>0.672109</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         rf__ccp_alpha  rf__max_depth rf__max_features  rf__min_samples_split  \\\n",
       "model_1         0.0010              4             auto                      3   \n",
       "model_2         0.0010              5             auto                      3   \n",
       "model_3         0.0001              6             auto                      2   \n",
       "model_4         0.0001              9             auto                      3   \n",
       "model_5         0.0001             15             auto                      2   \n",
       "model_6         0.0001             30             auto                      3   \n",
       "\n",
       "         rf__n_estimators  tvec__max_features tvec__ngram_range  \\\n",
       "model_1               120                2000            (1, 1)   \n",
       "model_2               120                2000            (1, 1)   \n",
       "model_3               120                2000            (1, 1)   \n",
       "model_4               140                2000            (1, 1)   \n",
       "model_5               140                2000            (1, 1)   \n",
       "model_6               120                2000            (1, 1)   \n",
       "\n",
       "                                          tvec__stop_words  training_score  \\\n",
       "model_1                                               None        0.638569   \n",
       "model_2                                               None        0.639303   \n",
       "model_3                                               None        0.643127   \n",
       "model_4                                               None        0.651806   \n",
       "model_5  [i, me, my, myself, we, our, ours, ourselves, ...        0.668725   \n",
       "model_6  [i, me, my, myself, we, our, ours, ourselves, ...        0.686671   \n",
       "\n",
       "         test_score  \n",
       "model_1    0.632833  \n",
       "model_2    0.628861  \n",
       "model_3    0.634157  \n",
       "model_4    0.643866  \n",
       "model_5    0.667255  \n",
       "model_6    0.672109  "
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reset the model params each time the cell is run\n",
    "model_params_rf = model_params_rf\n",
    "count_rf = count_rf\n",
    "\n",
    "# Set up the pipeline and params to tune\n",
    "pipe_rf = Pipeline([\n",
    "    ('tvec', TfidfVectorizer()),\n",
    "    ('rf', RandomForestClassifier())\n",
    "])\n",
    "\n",
    "params_rf = {\n",
    "    'tvec__stop_words'     : [None, stop_words, stop_words_plus],\n",
    "#     'tvec__min_df'         : [1.0, 2.0],\n",
    "    'tvec__max_features'   : [2000],\n",
    "    'tvec__ngram_range'    : [(1, 1), (1, 2)],\n",
    "    'rf__n_estimators'     : [120, 140],\n",
    "    'rf__max_depth'        : [15, 20, 30, 35],\n",
    "    'rf__max_features'     : ['auto'],\n",
    "    'rf__min_samples_split': [2, 3, 4],\n",
    "    'rf__ccp_alpha'        : [0.0001, 0.001] \n",
    "}\n",
    "\n",
    "# Perform gridsearch\n",
    "grid_rf = GridSearchCV(pipe_rf, param_grid=params_rf, n_jobs=-1, cv=5, verbose=2)\n",
    "\n",
    "grid_rf.fit(X_train, y_train)\n",
    "\n",
    "# Stole this part from the lesson on Random Forests - all credit to Patrick here\n",
    "count_rf += 1\n",
    "\n",
    "grid_rf.best_params_['training_score'] = grid_rf.best_score_\n",
    "model_params_rf[f'model_{count_rf}'] = grid_rf.best_params_\n",
    "grid_rf.best_params_['test_score'] = grid_rf.score(X_test, y_test)\n",
    "\n",
    "model_df = pd.DataFrame.from_dict(model_params_rf, orient='index')\n",
    "model_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3572c7e-b602-4d12-b6c8-a7afd8d66e96",
   "metadata": {},
   "source": [
    "This model is not performing well, even after several rounds of hyperparameter tuning. As you can see, the best accuracy I got was 68%  on the training set and 67%  on the test set. At least the model isn't overfit!\n",
    "\n",
    "To get a better idea of this model's performance, I will employ sklearn's `ClassificationReport`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "0434cd6d-657a-4bd6-8676-dba37ae3dcaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_preds_rf = grid_rf.predict(X_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "27566b64-2c97-43c5-be3f-812630bf81bc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "Conservative       0.64      0.79      0.71      1146\n",
      "  neoliberal       0.72      0.55      0.63      1120\n",
      "\n",
      "    accuracy                           0.67      2266\n",
      "   macro avg       0.68      0.67      0.67      2266\n",
      "weighted avg       0.68      0.67      0.67      2266\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_preds_rf, target_names=['Conservative', 'neoliberal']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a1ee814-e88f-4a91-bd55-cefe8db41c51",
   "metadata": {},
   "source": [
    "The precision and recall of this model were 0.68 and 0.67, respectively."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce882336-c426-49e0-a3c6-2b78faed7dc9",
   "metadata": {},
   "source": [
    "### The Naive Bayes Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "aad3873e-6acb-4431-8c4c-809cf0f0cc6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_params_nb = {}\n",
    "count_nb = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "dd945290-c907-406a-9b56-bed1deaf3f76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 240 candidates, totalling 1200 fits\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nb__alpha</th>\n",
       "      <th>nb__fit_prior</th>\n",
       "      <th>tvec__max_features</th>\n",
       "      <th>tvec__ngram_range</th>\n",
       "      <th>tvec__stop_words</th>\n",
       "      <th>training_score</th>\n",
       "      <th>test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>model_1</th>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>4000</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>[i, me, my, myself, we, our, ours, ourselves, ...</td>\n",
       "      <td>0.721094</td>\n",
       "      <td>0.716240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model_2</th>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>6000</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>[i, me, my, myself, we, our, ours, ourselves, ...</td>\n",
       "      <td>0.724772</td>\n",
       "      <td>0.720653</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         nb__alpha  nb__fit_prior  tvec__max_features tvec__ngram_range  \\\n",
       "model_1          1           True                4000            (1, 1)   \n",
       "model_2          1           True                6000            (1, 1)   \n",
       "\n",
       "                                          tvec__stop_words  training_score  \\\n",
       "model_1  [i, me, my, myself, we, our, ours, ourselves, ...        0.721094   \n",
       "model_2  [i, me, my, myself, we, our, ours, ourselves, ...        0.724772   \n",
       "\n",
       "         test_score  \n",
       "model_1    0.716240  \n",
       "model_2    0.720653  "
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reset the model params each time the cell is run\n",
    "model_params_nb = model_params_nb\n",
    "count_nb = count_nb\n",
    "\n",
    "# Set up the pipeline and params to tune\n",
    "pipe_nb = Pipeline([\n",
    "    ('tvec', TfidfVectorizer()),\n",
    "    ('nb', MultinomialNB())\n",
    "])\n",
    "\n",
    "params_nb = {\n",
    "    'tvec__stop_words'     : [None, stop_words, stop_words_plus],\n",
    "#     'tvec__min_df'         : [1.0, 2.0],\n",
    "    'tvec__max_features'   : [2000, 4000, 5000, 6000],\n",
    "    'tvec__ngram_range'    : [(1, 1), (1, 2)],\n",
    "    'nb__alpha'            : [0, 0.4, 0.6, 0.8, 1],\n",
    "    'nb__fit_prior'        : [True, False]\n",
    "}\n",
    "\n",
    "# Perform gridsearch\n",
    "grid_nb = GridSearchCV(pipe_nb, param_grid=params_nb, n_jobs=-1, cv=5, verbose=1)\n",
    "\n",
    "grid_nb.fit(X_train, y_train)\n",
    "\n",
    "# Stole this part from the lesson on Random Forests - all credit to Patrick here\n",
    "count_nb += 1\n",
    "\n",
    "grid_nb.best_params_['training_score'] = grid_nb.best_score_\n",
    "model_params_nb[f'model_{count_nb}'] = grid_nb.best_params_\n",
    "grid_nb.best_params_['test_score'] = grid_nb.score(X_test, y_test)\n",
    "\n",
    "model_df_nb = pd.DataFrame.from_dict(model_params_nb, orient='index')\n",
    "model_df_nb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2a73292-160b-448f-95d4-097abc8d7dfb",
   "metadata": {},
   "source": [
    "This model certainly performed better than the random forest regressor, but the accuracy of this model is still not fantastic at 72%. Once again, this model has a bias issue.\n",
    "\n",
    "Below is the `ClassificationReport` for this model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "d1a22548-3fe4-48fd-aedc-6a8d1545acbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_preds_nb = grid_nb.predict(X_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "98a734bf-cdee-4f05-8770-44b9a5a26760",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "Conservative       0.70      0.77      0.74      1146\n",
      "  neoliberal       0.74      0.67      0.70      1120\n",
      "\n",
      "    accuracy                           0.72      2266\n",
      "   macro avg       0.72      0.72      0.72      2266\n",
      "weighted avg       0.72      0.72      0.72      2266\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_preds_nb, target_names=['Conservative', 'neoliberal']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66199972-f3ec-45a9-a0d9-a4c285459b45",
   "metadata": {},
   "source": [
    "For this model, the precision and recall also increased to 0.72, the same value as the accuracy of the model. This also highlights the fact that the classes of the data were very well balanced."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0493dd95-f12a-4ae2-b16b-0fbca6de895a",
   "metadata": {},
   "source": [
    "### The Kernel SVM Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6ebef41-952f-4fd7-91b4-8255f083bbbe",
   "metadata": {},
   "source": [
    "Since the previous two models hit a score ceiling, I will instead try to fit the data to a SVM model. In this case, the SVM will use a second order polynomial kernel to better classify the data. The process for creating this model will be very similar to the workflows for the previous two models\n",
    "\n",
    "*Note:* Since the output of the TF-IDF vectorizer is a matrix scaled to the inverse frequency of words across the corpus, I shouldn't need to scale the data beforehand, but I'm going to try this anyways to see if it will improve performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "3cf5a403-bb0d-4abb-b29a-ec65f5e7fb94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import SVM\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "33dd224b-2e03-4285-b1f8-466b1bbc188d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Providing the basic framework for the modelisklearn.preprocessingmodel_params_svc = {}\n",
    "count_svc = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "c106b2ed-54f1-4ba1-9516-89c507acf953",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 240 candidates, totalling 1200 fits\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>svc__C</th>\n",
       "      <th>svc__degree</th>\n",
       "      <th>svc__gamma</th>\n",
       "      <th>tvec__max_features</th>\n",
       "      <th>tvec__ngram_range</th>\n",
       "      <th>tvec__stop_words</th>\n",
       "      <th>training_score</th>\n",
       "      <th>test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>model_1</th>\n",
       "      <td>2.222311</td>\n",
       "      <td>2</td>\n",
       "      <td>scale</td>\n",
       "      <td>6000</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>None</td>\n",
       "      <td>0.719181</td>\n",
       "      <td>0.736099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model_2</th>\n",
       "      <td>2.231111</td>\n",
       "      <td>2</td>\n",
       "      <td>scale</td>\n",
       "      <td>8000</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>None</td>\n",
       "      <td>0.722711</td>\n",
       "      <td>0.740071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model_3</th>\n",
       "      <td>17.778889</td>\n",
       "      <td>2</td>\n",
       "      <td>scale</td>\n",
       "      <td>8000</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>None</td>\n",
       "      <td>0.666959</td>\n",
       "      <td>0.675199</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            svc__C  svc__degree svc__gamma  tvec__max_features  \\\n",
       "model_1   2.222311            2      scale                6000   \n",
       "model_2   2.231111            2      scale                8000   \n",
       "model_3  17.778889            2      scale                8000   \n",
       "\n",
       "        tvec__ngram_range tvec__stop_words  training_score  test_score  \n",
       "model_1            (1, 1)             None        0.719181    0.736099  \n",
       "model_2            (1, 1)             None        0.722711    0.740071  \n",
       "model_3            (1, 2)             None        0.666959    0.675199  "
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reset the model params each time the cell is run\n",
    "model_params_svc = model_params_svc\n",
    "count_svc = count_svc\n",
    "\n",
    "# Set up the pipeline and params to tune\n",
    "pipe_svc = Pipeline([\n",
    "    ('tvec', TfidfVectorizer()),\n",
    "    ('sc', StandardScaler(with_mean=False)), # This prevents an error with the sparse array\n",
    "    ('svc', SVC(kernel='poly'))\n",
    "])\n",
    "\n",
    "params_svc = {\n",
    "    'tvec__stop_words'     : [None, stop_words, stop_words_plus],\n",
    "    'tvec__max_features'   : [6000, 8000],\n",
    "    'tvec__ngram_range'    : [(1, 1), (1, 2)],\n",
    "    'svc__C'               : np.linspace(0.01, 20, 10),\n",
    "    'svc__gamma'           : ['scale', 'auto'],\n",
    "    'svc__degree'          : [2]\n",
    "}\n",
    "\n",
    "# Perform gridsearch\n",
    "grid_svc = GridSearchCV(pipe_svc, param_grid=params_svc, n_jobs=-1, cv=5, verbose=1)\n",
    "\n",
    "grid_svc.fit(X_train, y_train)\n",
    "\n",
    "# Stole this part from the lesson on Random Forests - all credit to Patrick here\n",
    "count_svc += 1\n",
    "\n",
    "grid_svc.best_params_['training_score'] = grid_svc.best_score_\n",
    "model_params_svc[f'model_{count_svc}'] = grid_svc.best_params_\n",
    "grid_svc.best_params_['test_score'] = grid_svc.score(X_test, y_test)\n",
    "\n",
    "model_df_svc = pd.DataFrame.from_dict(model_params_svc, orient='index')\n",
    "model_df_svc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "edfeaf9c-6cef-4883-abc3-4eac77a73e99",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_preds_svc = grid_svc.predict(X_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "87e0b412-8c81-4a18-9c74-950dc0f2f445",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "Conservative       0.73      0.77      0.75      1146\n",
      "  neoliberal       0.75      0.71      0.73      1120\n",
      "\n",
      "    accuracy                           0.74      2266\n",
      "   macro avg       0.74      0.74      0.74      2266\n",
      "weighted avg       0.74      0.74      0.74      2266\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_preds_svc, target_names=['Conservative', 'neoliberal']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3730e06-95ad-4789-b1fb-b59f54fce941",
   "metadata": {},
   "source": [
    "SVM did offer an improvement over the other two models, but only by *2 percent*. Another interesting thing that I was not expecting from this model was the lower accuracy when `StandardScaler` was included in the pipeline - usually, scaling your data makes an SVM perform better. I suppose this reinforces my original hypothesis that the vectorized text data would not need to be scaled for SVM to perform well.\n",
    "\n",
    "For this model, the accuracy (on the test set), the recall. and precision were all 0.74. The accuracy on the test set was actually better than on the training set (0.72)!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c20b2d9-6705-4587-a2ab-9b54a5b57e0b",
   "metadata": {},
   "source": [
    "## Results\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceb18c85-790c-4cc8-881e-25ce712c7bb6",
   "metadata": {},
   "source": [
    "In the end, I was able to create a classification model that could predict on unseen subreddit posts from r/neoliberal and r/Conservative and classify them into these categories. However, the best performing SVM model only had an accuracy of 0.74 on unseen data.\n",
    "\n",
    "I believe the main factor that kept the score down here was the fact that r/neoliberal and r/Conservative have similar post titles and descriptions. Recall that the top ten words from both subreddits included \"Biden\", \"Trump\" and \"US.\" The models therefore had a difficult time differentiating  between the two subreddits. Despite the difference in talking points and overall politics, the tone and vocabulary of both subreddits are very similar."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc522235-81a8-4df2-aa47-2c4178c70547",
   "metadata": {},
   "source": [
    "## Conclusions and Next Steps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d26bcce-d818-4c6d-ba0b-ca7818b99332",
   "metadata": {},
   "source": [
    "Based on the findings above, I would recommend that the Pushshift archiving team use this model to sort through the mixed up 2020 data in *chunks*, as to make sure the misclassifications the model produces can be caught and corrected before moving on. This should make the task of cleaning up the clerical error much simpler, although it isn't the cleanest solution.\n",
    "\n",
    "If there was more time to create further models, I might instead recommend using a more powerful model, such as a neural net, to more accurately classify the posts. The process for training a neural net would likely take a long time to complete, however, and I'm not familiar enough with neural nets to be able to make one from scratch at this time.\n",
    "\n",
    "Another idea would be to introduce more complexity into the models. The bias on all of these models was high, so there could be a lot of room for score improvements if this is done. I think this is especially relevant for the Random Forest Regressor, as increasing the complexity of the model via `max_depth` led to good score improvements. Out of all three models, the Random Forest Classifier showed the most improvement with iterative hyperparameter tuning. The main issue with more tuning, however, is the *significant* time sink grid searching each model presents.\n",
    "\n",
    "One more thing to consider is the fact that the data used for these models is very perishable. Political discourse changes all the time as the issues facing the world change. I chose to scape posts from early 2021 for this reason - I believe that this time period best captures the political discourse of late 2020, from the 2020 US elections to the COVID-19 pandemic. Trying to classify the 2020 posts with data from another year would result in low accuracy, and trying to classify posts, from say, 2018 based on 2021 data would also result in low accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58410a53-7328-4562-a8f2-1ab9023013eb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
